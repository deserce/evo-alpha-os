# backend/quant_engine/features/calc_indicators.py

import sys
import os
import time
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta, date
from sqlalchemy import text

# ================= ç¯å¢ƒè·¯å¾„é€‚é… =================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../"))
if project_root not in sys.path:
    sys.path.append(project_root)

from app.core.database import get_engine

# ================= é…ç½® =================
PERIODS = [3, 5, 10, 20, 50, 120, 250]
TABLE_SOURCE = "stock_daily_prices"
TABLE_TARGET = "quant_feature_rps"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class IndicatorCalculator:
    def __init__(self):
        self.engine = get_engine()

    def load_data(self, start_date=None):
        """åŠ è½½ K çº¿æ•°æ®"""
        # å¦‚æœæŒ‡å®šäº† start_dateï¼ŒåªåŠ è½½é‚£ä¹‹åçš„æ•°æ®ï¼ˆå¢é‡æ¨¡å¼ï¼‰
        # å¦åˆ™åŠ è½½å…¨é‡
        condition = f"WHERE trade_date >= '{start_date}'" if start_date else ""
        
        query = f"""
            SELECT symbol, trade_date, close 
            FROM {TABLE_SOURCE} 
            {condition}
            ORDER BY trade_date
        """
        logger.info(f"ğŸ“¥ æ­£åœ¨è¯»å–æ•°æ® (Start: {start_date if start_date else 'All'})...")
        df = pd.read_sql(query, self.engine)
        
        if df.empty: return df
        
        df['trade_date'] = pd.to_datetime(df['trade_date'])
        return df

    def compute_features(self, df):
        """æ ¸å¿ƒè®¡ç®—é€»è¾‘ (å‘é‡åŒ–)"""
        if df.empty: return pd.DataFrame()

        # 1. Pivot å®½è¡¨
        df_pivot = df.pivot(index='trade_date', columns='symbol', values='close')
        df_pivot = df_pivot.fillna(method='ffill') # å¡«å……åœç‰Œ
        
        # 2. è®¡ç®—æ¶¨å¹… & RPS
        feature_dfs = []
        
        for n in PERIODS:
            # æ¶¨å¹…
            chg = df_pivot.pct_change(n)
            # RPS æ’å (0-100)
            rps = chg.rank(axis=1, pct=True, method='min') * 100
            
            # å †å 
            chg_stack = chg.stack().reset_index()
            chg_stack.columns = ['trade_date', 'symbol', f'chg_{n}']
            chg_stack.set_index(['symbol', 'trade_date'], inplace=True)
            
            rps_stack = rps.stack().reset_index()
            rps_stack.columns = ['trade_date', 'symbol', f'rps_{n}']
            rps_stack.set_index(['symbol', 'trade_date'], inplace=True)
            
            feature_dfs.append(chg_stack)
            feature_dfs.append(rps_stack)
            
        # 3. åˆå¹¶
        final_df = pd.concat(feature_dfs, axis=1).reset_index()
        
        # 4. æ ¼å¼åŒ–
        float_cols = [c for c in final_df.columns if c not in ['symbol', 'trade_date']]
        for c in float_cols:
            if 'rps' in c:
                final_df[c] = final_df[c].round(2)
            else:
                final_df[c] = final_df[c].round(4)
                
        return final_df

    def save_to_db(self, df, mode='append'):
        """å…¥åº“é€»è¾‘"""
        if df.empty: return
        
        logger.info(f"ğŸ’¾ æ­£åœ¨å†™å…¥æ•°æ®åº“ ({len(df)} è¡Œ)...")
        try:
            # å¦‚æœæ˜¯ append (å¢é‡)ï¼Œéœ€è¦é˜²æ­¢ä¸»é”®å†²çª
            # Pandas çš„ to_sql append é‡åˆ°ä¸»é”®å†²çªä¼šæŠ¥é”™
            # æ‰€ä»¥å¢é‡æ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬è¦å…ˆåˆ æ‰å½“å¤©å·²æœ‰çš„æ•°æ® (å¹‚ç­‰æ€§)
            if mode == 'append':
                dates = df['trade_date'].unique()
                # æ ¼å¼åŒ–æ—¥æœŸåˆ—è¡¨
                date_strs = [pd.to_datetime(d).strftime('%Y-%m-%d') for d in dates]
                if date_strs:
                    date_list_sql = "'" + "','".join(date_strs) + "'"
                    with self.engine.begin() as conn:
                        conn.execute(text(f"DELETE FROM {TABLE_TARGET} WHERE trade_date IN ({date_list_sql})"))
            
            # å¦‚æœæ˜¯ replace (å…¨é‡)ï¼Œå¤–éƒ¨éœ€è¦åœ¨è°ƒç”¨å‰ truncateï¼Œè¿™é‡Œåªç®¡ append
            df.to_sql(TABLE_TARGET, self.engine, if_exists='append', index=False, method='multi', chunksize=5000)
            
        except Exception as e:
            logger.error(f"âŒ å…¥åº“å¤±è´¥: {e}")
            # å¦‚æœæ˜¯æ­»é”æˆ–è€…ç½‘ç»œé—®é¢˜ï¼Œå¯èƒ½éœ€è¦é‡è¯•æœºåˆ¶ï¼Œè¿™é‡Œæš‚ç•¥

    def run_init(self):
        """ã€å…¨é‡æ¨¡å¼ã€‘é‡ç®—æ‰€æœ‰å†å²"""
        logger.info("ğŸš€ [RPS] å¯åŠ¨å…¨é‡é‡ç®—...")
        
        # 1. æ¸…ç©ºè¡¨
        with self.engine.begin() as conn:
            conn.execute(text(f"TRUNCATE TABLE {TABLE_TARGET}"))
            
        # 2. åŠ è½½å…¨é‡
        df = self.load_data(start_date=None)
        
        # 3. è®¡ç®—
        res = self.compute_features(df)
        
        # 4. ä¿å­˜
        self.save_to_db(res, mode='replace_fast') # å®é™…ä¸Šä¹Ÿæ˜¯appendï¼Œåªæ˜¯å‰é¢æ¸…ç©ºäº†
        logger.info("âœ… å…¨é‡ä»»åŠ¡å®Œæˆ")

    def run_daily(self):
        """ã€å¢é‡æ¨¡å¼ã€‘åªç®—æœ€æ–°ä¸€å¤©"""
        logger.info("ğŸš€ [RPS] å¯åŠ¨å¢é‡æ›´æ–°...")
        
        # 1. ç¡®å®šæ•°æ®åŠ è½½çª—å£
        # æˆ‘ä»¬éœ€è¦è®¡ç®— 250æ—¥ RPSï¼Œæ‰€ä»¥è‡³å°‘éœ€è¦å¾€å‰æ¨ 250ä¸ªäº¤æ˜“æ—¥
        # ä¿é™©èµ·è§ï¼Œå¾€å‰æ¨ 400 ä¸ªè‡ªç„¶æ—¥
        cutoff_date = (datetime.now() - timedelta(days=400)).strftime("%Y-%m-%d")
        
        # 2. åŠ è½½â€œæ»‘åŠ¨çª—å£â€æ•°æ®
        df = self.load_data(start_date=cutoff_date)
        if df.empty: return

        # 3. è®¡ç®— (æ­¤æ—¶ç®—å‡ºæ¥çš„æ˜¯è¿‡å»400å¤©çš„RPS)
        res_full = self.compute_features(df)
        
        # 4. æˆªå–æœ€æ–°æ•°æ®
        # å‡è®¾ä»Šå¤©æ˜¯ 2025-01-01ï¼Œæˆ‘ä»¬åªéœ€è¦å­˜ 2025-01-01 çš„ç»“æœ
        # ä½†è€ƒè™‘åˆ°å¯èƒ½è¡¥æ¼ï¼Œæˆ‘ä»¬å–æœ€è¿‘ 3 å¤©çš„æ•°æ®å…¥åº“
        target_date_threshold = (datetime.now() - timedelta(days=3))
        res_daily = res_full[res_full['trade_date'] > target_date_threshold].copy()
        
        if res_daily.empty:
            logger.info("âš ï¸ æ— æœ€æ–°æ—¥æœŸæ•°æ®éœ€è¦æ›´æ–° (å¯èƒ½æ˜¯å‡æœŸ)")
            return
            
        logger.info(f"ğŸ“… æ•è·æ›´æ–°æ—¥æœŸ: {res_daily['trade_date'].unique()}")
        
        # 5. ä¿å­˜
        self.save_to_db(res_daily, mode='append')
        logger.info("âœ… å¢é‡ä»»åŠ¡å®Œæˆ")

if __name__ == "__main__":
    import argparse
    
    # ç®€å•çš„å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶
    # python calc_indicators.py --mode=init  (å…¨é‡)
    # python calc_indicators.py              (é»˜è®¤å¢é‡)
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', type=str, default='daily', help='init or daily')
    args = parser.parse_args()
    
    calc = IndicatorCalculator()
    if args.mode == 'init':
        calc.run_init()
    else:
        calc.run_daily()