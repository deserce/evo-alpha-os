"""
EvoAlpha OS - å› å­è®¡ç®—åŸºç±»
æä¾›ç»Ÿä¸€çš„RPSè®¡ç®—æ¡†æ¶ï¼Œæ”¯æŒä¸ªè‚¡ã€æ¿å—ã€ETFç­‰ä¸åŒæ ‡çš„ç±»å‹
"""

import sys
import os
import time
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from abc import ABC, abstractmethod
from sqlalchemy import text

# ================= ç¯å¢ƒè·¯å¾„é€‚é… =================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../"))
if project_root not in sys.path:
    sys.path.append(project_root)

# ================= å…¬å…±å·¥å…·å¯¼å…¥ =================
from quant_engine.common import setup_quant_path, setup_logger
from quant_engine.common.exception_utils import CalculationError, DataSourceError, ValidationError
from quant_engine.config.calculator_config import CalculatorConfig

# ================= è·¯å¾„åˆå§‹åŒ– =================
setup_quant_path()

# ================= Loggeré…ç½® =================
logger = setup_logger(__name__, level=CalculatorConfig.LOG_LEVEL)


class BaseFeatureCalculator(ABC):
    """
    å› å­è®¡ç®—åŸºç±»

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ç»Ÿä¸€çš„æ•°æ®åŠ è½½ï¼ˆæ”¯æŒå¢é‡çª—å£ï¼‰
    2. é€šç”¨çš„RPSè®¡ç®—é€»è¾‘ï¼ˆå‘é‡åŒ–ï¼‰
    3. æ ‡å‡†åŒ–çš„ä¿å­˜é€»è¾‘ï¼ˆå¹‚ç­‰æ€§ï¼‰
    4. å®Œæ•´çš„æ—¥å¿—è®°å½•

    è®¾è®¡åŸåˆ™ï¼š
    - å­ç±»åªéœ€å®ç°é…ç½®æ–¹æ³•ï¼Œè®¡ç®—é€»è¾‘å…¨éƒ¨å¤ç”¨
    - ç»Ÿä¸€å‘½åè§„èŒƒï¼Œä¾¿äºç†è§£å’Œç»´æŠ¤
    """

    def __init__(self):
        """åˆå§‹åŒ–è®¡ç®—å™¨"""
        from app.core.database import get_engine
        self.engine = get_engine()
        self.config = CalculatorConfig()

        # è·å–å­ç±»é…ç½®
        self.source_table = self.get_source_table()
        self.target_table = self.get_target_table()
        self.entity_column = self.get_entity_column()
        self.periods = self.get_periods()

    # ================= æŠ½è±¡æ–¹æ³•ï¼ˆå­ç±»å¿…é¡»å®ç°ï¼‰ =================

    @abstractmethod
    def get_source_table(self) -> str:
        """è¿”å›æºè¡¨å"""
        pass

    @abstractmethod
    def get_target_table(self) -> str:
        """è¿”å›ç›®æ ‡è¡¨å"""
        pass

    @abstractmethod
    def get_entity_column(self) -> str:
        """è¿”å›æ ‡çš„åˆ—åï¼ˆsymbol/sector_nameï¼‰"""
        pass

    @abstractmethod
    def get_periods(self) -> list[int]:
        """è¿”å›è®¡ç®—å‘¨æœŸåˆ—è¡¨"""
        pass

    def should_filter(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ•°æ®è¿‡æ»¤é€»è¾‘ï¼ˆå¯é€‰ï¼Œå­ç±»å¯è¦†ç›–ï¼‰

        Args:
            df: åŸå§‹æ•°æ®

        Returns:
            pd.DataFrame: è¿‡æ»¤åçš„æ•°æ®
        """
        return df

    # ================= æ ¸å¿ƒæ–¹æ³•ï¼ˆé€šç”¨é€»è¾‘ï¼‰ =================

    def _init_table(self):
        """åˆå§‹åŒ–ç›®æ ‡è¡¨ç»“æ„"""
        if self.target_table.startswith('quant_feature_'):
            # æ ‡å‡†åŒ–çš„é‡åŒ–å› å­è¡¨ç»“æ„
            # å‰ä¸¤åˆ—ï¼ˆentity_column å’Œ trade_dateï¼‰éœ€è¦ç‰¹æ®Šç±»å‹
            fields_str = f"    {self.entity_column} TEXT,\n    trade_date TEXT"

            # æ·»åŠ æ¶¨å¹…å­—æ®µï¼ˆFLOATç±»å‹ï¼‰
            for period in self.periods:
                fields_str += f",\n    chg_{period} FLOAT"

            # æ·»åŠ RPSå­—æ®µï¼ˆFLOATç±»å‹ï¼‰
            for period in self.periods:
                fields_str += f",\n    rps_{period} FLOAT"

            primary_key = f'{self.entity_column}, trade_date'

            with self.engine.begin() as conn:
                conn.execute(text(f"""
                    CREATE TABLE IF NOT EXISTS {self.target_table} (
                        {fields_str},
                        PRIMARY KEY ({primary_key})
                    );
                """))
                conn.execute(text(f"CREATE INDEX IF NOT EXISTS idx_{self.target_table}_date ON {self.target_table} (trade_date);"))

            logger.info(f"âœ… è¡¨ {self.target_table} åˆå§‹åŒ–å®Œæˆ")
        else:
            logger.warning(f"âš ï¸ è·³è¿‡è¡¨åˆå§‹åŒ–ï¼ˆéæ ‡å‡†è¡¨åï¼‰")

    def load_data(self, start_date=None):
        """
        åŠ è½½æ•°æ®ï¼ˆæ”¯æŒå¢é‡çª—å£ï¼‰

        Args:
            start_date: èµ·å§‹æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰ï¼ŒNoneè¡¨ç¤ºåŠ è½½å…¨é‡

        Returns:
            pd.DataFrame: åŠ è½½çš„æ•°æ®
        """
        condition = f"WHERE trade_date >= '{start_date}'" if start_date else ""
        query = f"""
            SELECT {self.entity_column}, trade_date, close
            FROM {self.source_table}
            {condition}
            ORDER BY trade_date
        """

        logger.info(f"ğŸ“¥ æ­£åœ¨è¯»å–æ•°æ® (Start: {start_date if start_date else 'All'})...")

        try:
            df = pd.read_sql(query, self.engine)
        except Exception as e:
            raise DataSourceError(f"è¯»å–æ•°æ®å¤±è´¥: {e}")

        if df.empty:
            logger.warning("âš ï¸ æ•°æ®ä¸ºç©º")
            return df

        df['trade_date'] = pd.to_datetime(df['trade_date'])

        # è®°å½•åŠ è½½ç»Ÿè®¡
        entity_count = df[self.entity_column].nunique()
        date_range = f"{df['trade_date'].min().date()} è‡³ {df['trade_date'].max().date()}"
        logger.info(f"   âœ… åŠ è½½å®Œæˆ: {len(df)} è¡Œ, {entity_count} ä¸ªæ ‡çš„, {date_range}")

        return df

    def compute_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ¸å¿ƒè®¡ç®—é€»è¾‘ï¼ˆå‘é‡åŒ–ï¼‰

        Args:
            df: åŸå§‹Kçº¿æ•°æ®

        Returns:
            pd.DataFrame: è®¡ç®—åçš„å› å­æ•°æ®
        """
        if df.empty:
            raise ValidationError("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—å› å­")

        logger.info("ğŸ§® å¼€å§‹è®¡ç®—RPSå› å­...")

        # 1. åº”ç”¨å­ç±»è¿‡æ»¤é€»è¾‘
        df_filtered = self.should_filter(df)
        if len(df_filtered) < len(df):
            logger.info(f"   ğŸ§¹ è¿‡æ»¤å: {len(df_filtered)} è¡Œ (åŸå§‹: {len(df)} è¡Œ)")

        # 2. Pivot å®½è¡¨
        df_pivot = df_filtered.pivot(
            index='trade_date',
            columns=self.entity_column,
            values='close'
        )
        df_pivot = df_pivot.fillna(method='ffill')  # å¡«å……åœç‰Œ

        logger.info(f"   ğŸ“Š Pivotè¡¨å½¢çŠ¶: {df_pivot.shape}")

        # 3. è®¡ç®—RPSå’Œæ¶¨å¹…
        feature_dfs = []

        for period in self.periods:
            # æ¶¨å¹…
            chg = df_pivot.pct_change(period)
            # RPS (æ’åç™¾åˆ†æ¯” 0-100)
            rps = chg.rank(axis=1, pct=True, method='min') * 100

            # Stack å †å 
            chg_stack = chg.stack().reset_index()
            chg_stack.columns = ['trade_date', self.entity_column, f'chg_{period}']
            chg_stack.set_index([self.entity_column, 'trade_date'], inplace=True)

            rps_stack = rps.stack().reset_index()
            rps_stack.columns = ['trade_date', self.entity_column, f'rps_{period}']
            rps_stack.set_index([self.entity_column, 'trade_date'], inplace=True)

            feature_dfs.append(chg_stack)
            feature_dfs.append(rps_stack)

        # 4. åˆå¹¶
        df_final = pd.concat(feature_dfs, axis=1).reset_index()

        # 5. ç¡®ä¿åˆ—é¡ºåºæ­£ç¡®ï¼ˆä¸è¡¨ç»“æ„ä¸€è‡´ï¼‰
        # æ„å»ºæ­£ç¡®çš„åˆ—é¡ºåºï¼šentity_column, trade_date, chg_x, rps_x, chg_y, rps_y, ...
        ordered_columns = [self.entity_column, 'trade_date']
        for period in self.periods:
            ordered_columns.append(f'chg_{period}')
            ordered_columns.append(f'rps_{period}')

        # åªä¿ç•™å­˜åœ¨çš„åˆ—ï¼ˆé˜²æ­¢æŸäº›åˆ—ç¼ºå¤±ï¼‰
        ordered_columns = [col for col in ordered_columns if col in df_final.columns]
        df_final = df_final[ordered_columns]

        # 6. æ ¼å¼åŒ–
        float_cols = [c for c in df_final.columns if c not in [self.entity_column, 'trade_date']]
        for col in float_cols:
            if 'rps' in col:
                df_final[col] = df_final[col].round(2)
            else:
                df_final[col] = df_final[col].round(4)

        logger.info(f"   âœ… è®¡ç®—å®Œæˆ: {len(df_final)} è¡Œ, {len(float_cols)} ä¸ªå› å­")

        return df_final

    def save_to_db(self, df: pd.DataFrame, mode: str = 'append'):
        """
        ä¿å­˜æ•°æ®åˆ°æ•°æ®åº“ï¼ˆå¹‚ç­‰æ€§ï¼‰

        Args:
            df: è¦ä¿å­˜çš„æ•°æ®
            mode: 'append' æˆ– 'replace'
        """
        if df.empty:
            logger.warning("âš ï¸ æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ä¿å­˜")
            return

        logger.info(f"ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {self.target_table} ({len(df)} è¡Œ)...")

        try:
            # å¹‚ç­‰æ€§åˆ é™¤ï¼šåˆ é™¤å½“å¤©çš„æ•°æ®
            if mode == 'append':
                dates = df['trade_date'].unique()
                date_strs = [pd.to_datetime(d).strftime('%Y-%m-%d') for d in dates]
                if date_strs:
                    with self.engine.begin() as conn:
                        for date_str in date_strs:
                            # ä½¿ç”¨ LIKE åŒ¹é…æ—¥æœŸï¼ˆå¤„ç†å¸¦æ—¶é—´æˆ³çš„æ—¥æœŸï¼‰
                            conn.execute(text(f"""
                                DELETE FROM {self.target_table}
                                WHERE trade_date LIKE '{date_str}%'
                            """))

            # å»é™¤DataFrameå†…éƒ¨çš„é‡å¤è®°å½•ï¼ˆä¿ç•™æœ€åä¸€æ¡ï¼‰
            original_len = len(df)
            df = df.drop_duplicates(subset=[self.entity_column, 'trade_date'], keep='last')
            if len(df) < original_len:
                logger.info(f"   ğŸ§¹ å»é™¤é‡å¤: {original_len - len(df)} æ¡")

            # ä¿å­˜æ•°æ®
            df.to_sql(
                self.target_table,
                self.engine,
                if_exists='append',
                index=False,
                method='multi',
                chunksize=self.config.CHUNK_SIZE
            )

            logger.info(f"   âœ… ä¿å­˜æˆåŠŸ")

        except Exception as e:
            raise CalculationError(f"ä¿å­˜å¤±è´¥: {e}")

    def run_init(self, days=365):
        """
        ã€å…¨é‡æ¨¡å¼ã€‘é‡ç®—æŒ‡å®šå¤©æ•°çš„æ•°æ®ï¼ˆé»˜è®¤æœ€è¿‘ä¸€å¹´ï¼‰

        Args:
            days: åŠ è½½æœ€è¿‘Nå¤©çš„æ•°æ®ï¼Œé»˜è®¤365å¤©ï¼ˆä¸€å¹´ï¼‰

        ç”¨é€”ï¼š
        - é¦–æ¬¡åˆå§‹åŒ–
        - ä¿®å¤æ•°æ®é”™è¯¯
        - é‡ç®—æœ€è¿‘ä¸€å¹´çš„æ•°æ®
        """
        logger.info("=" * 80)
        logger.info(f"ğŸš€ [{self.__class__.__name__}] å¯åŠ¨å…¨é‡é‡ç®—ï¼ˆæœ€è¿‘{days}å¤©ï¼‰...")
        logger.info("=" * 80)

        start_time = time.time()

        try:
            # 1. åˆå§‹åŒ–è¡¨
            self._init_table()

            # 2. æ¸…ç©ºæ—§æ•°æ®
            logger.info(f"ğŸ—‘ï¸ æ¸…ç©ºè¡¨ {self.target_table}...")
            with self.engine.begin() as conn:
                conn.execute(text(f"DELETE FROM {self.target_table}"))

            # 3. è®¡ç®—èµ·å§‹æ—¥æœŸ
            cutoff_date = (
                datetime.now() - timedelta(days=days)
            ).strftime("%Y-%m-%d")
            logger.info(f"ğŸ“… æ•°æ®èŒƒå›´: {cutoff_date} è‡³ä»Š")

            # 4. åŠ è½½æ•°æ®
            df = self.load_data(start_date=cutoff_date)

            if df.empty:
                logger.warning("âš ï¸ æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡è®¡ç®—")
                return

            # 5. è®¡ç®—å› å­
            result = self.compute_features(df)

            # 6. ä¿å­˜
            self.save_to_db(result, mode='append')

            cost = time.time() - start_time
            logger.info(f"âœ… å…¨é‡ä»»åŠ¡å®Œæˆï¼è€—æ—¶: {cost:.1f}ç§’")

        except Exception as e:
            logger.error(f"âŒ å…¨é‡ä»»åŠ¡å¤±è´¥: {e}")
            raise

    def run_daily(self):
        """
        ã€å¢é‡æ¨¡å¼ã€‘åªç®—æœ€æ–°å‡ å¤©

        ç”¨é€”ï¼š
        - æ¯æ—¥å®šæ—¶ä»»åŠ¡
        - è¡¥å……ç¼ºå¤±æ•°æ®
        """
        logger.info("=" * 80)
        logger.info(f"ğŸš€ [{self.__class__.__name__}] å¯åŠ¨å¢é‡æ›´æ–°...")
        logger.info("=" * 80)

        start_time = time.time()

        try:
            # 1. åˆå§‹åŒ–è¡¨
            self._init_table()

            # 2. ç¡®å®šå¢é‡çª—å£
            cutoff_date = (
                datetime.now() - timedelta(days=self.config.INCREMENTAL_WINDOW_DAYS)
            ).strftime("%Y-%m-%d")

            logger.info(f"ğŸ“… å¢é‡çª—å£: {cutoff_date} è‡³ä»Š")

            # 3. åŠ è½½æ»‘åŠ¨çª—å£æ•°æ®
            df = self.load_data(start_date=cutoff_date)

            if df.empty:
                logger.info("âš ï¸ æ— æœ€æ–°æ•°æ®éœ€è¦æ›´æ–°ï¼ˆå¯èƒ½æ˜¯å‡æœŸï¼‰")
                return

            # 4. è®¡ç®—
            result_full = self.compute_features(df)

            # 5. æˆªå–æœ€è¿‘å‡ å¤©
            target_date_threshold = (
                datetime.now() - timedelta(days=self.config.SAVE_RECENT_DAYS)
            )
            result_daily = result_full[result_full['trade_date'] > target_date_threshold].copy()

            if result_daily.empty:
                logger.info("âš ï¸ æ— æœ€æ–°æ—¥æœŸæ•°æ®éœ€è¦æ›´æ–°")
                return

            logger.info(f"ğŸ“… æ•è·æ›´æ–°æ—¥æœŸ: {result_daily['trade_date'].unique()}")

            # 6. ä¿å­˜
            self.save_to_db(result_daily, mode='append')

            cost = time.time() - start_time
            logger.info(f"âœ… å¢é‡ä»»åŠ¡å®Œæˆï¼è€—æ—¶: {cost:.1f}ç§’")

        except Exception as e:
            logger.error(f"âŒ å¢é‡ä»»åŠ¡å¤±è´¥: {e}")
            raise

    def run(self, mode='daily'):
        """
        æ‰§è¡Œè®¡ç®—

        Args:
            mode: 'daily' æˆ– 'init'
        """
        if mode == 'init':
            self.run_init()
        else:
            self.run_daily()
