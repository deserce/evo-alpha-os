"""
EvoAlpha OS - æ¿å—Kçº¿æ•°æ®é‡‡é›†å™¨
é‡‡é›†æ¿å—æŒ‡æ•°çš„æ—¥çº§è¡Œæƒ…æ•°æ®
"""

import time
import pandas as pd
import akshare as ak
from sqlalchemy import text
from datetime import timedelta, datetime

# å…¬å…±å·¥å…·å¯¼å…¥
from data_job.common import setup_network_emergency_kit, setup_backend_path, setup_logger

# åŸºç±»å¯¼å…¥
from data_job.core.base_collector import BaseCollector

from app.core.database import get_engine

# è·¯å¾„å’Œç½‘ç»œåˆå§‹åŒ–
setup_backend_path()
setup_network_emergency_kit()

# Loggeré…ç½®
logger = setup_logger(__name__)


class SectorKlineCollector(BaseCollector):
    """æ¿å—Kçº¿æ•°æ®é‡‡é›†å™¨"""

    def __init__(self):
        super().__init__(
            collector_name="sector_kline",
            request_timeout=30,
            request_delay=0.05,
            max_retries=3
        )
        self.engine = get_engine()
        self.table_name = "sector_daily_prices"

    def _init_table(self):
        """ç¡®ä¿ç›®æ ‡è¡¨å­˜åœ¨"""
        with self.engine.begin() as conn:
            conn.execute(text(f"""
                CREATE TABLE IF NOT EXISTS {self.table_name} (
                    sector_name TEXT,
                    trade_date DATE,
                    open FLOAT,
                    close FLOAT,
                    high FLOAT,
                    low FLOAT,
                    volume FLOAT,
                    amount FLOAT,
                    pct_chg FLOAT,
                    PRIMARY KEY (sector_name, trade_date)
                );
            """))
            try:
                conn.execute(text(f"CREATE INDEX IF NOT EXISTS idx_sector_date ON {self.table_name} (trade_date);"))
            except Exception:
                pass

    def get_start_date(self, sector_name: str) -> str:
        """
        æ ¸å¿ƒé€»è¾‘ï¼šæ£€æŸ¥æ•°æ®åº“ï¼Œå†³å®šæ˜¯ã€å…¨é‡ä¸‹è½½ã€‘è¿˜æ˜¯ã€å¢é‡æ›´æ–°ã€‘
        è¿”å›æ ¼å¼: 'YYYYMMDD'
        """
        query = text(f"SELECT MAX(trade_date) FROM {self.table_name} WHERE sector_name = :name")
        try:
            with self.engine.connect() as conn:
                result = conn.execute(query, {"name": sector_name}).scalar()

            if result:
                # ç¡®ä¿æ˜¯ date å¯¹è±¡
                if isinstance(result, str):
                    result = datetime.strptime(result, '%Y-%m-%d').date()
                elif isinstance(result, datetime):
                    result = result.date()
                next_date = result + timedelta(days=1)
                return next_date.strftime("%Y%m%d")
            else:
                three_years_ago = (datetime.now() - timedelta(days=1095)).strftime("%Y%m%d")
                return three_years_ago
        except Exception as e:
            logger.warning(f"è·å–èµ·å§‹æ—¥æœŸå¤±è´¥ï¼Œé»˜è®¤ä¸‹è½½3å¹´æ•°æ®: {e}")
            three_years_ago = (datetime.now() - timedelta(days=1095)).strftime("%Y%m%d")
            return three_years_ago

    def fetch_data(self, name: str, s_type: str, start_date: str) -> pd.DataFrame:
        """è°ƒç”¨ AkShare æ¥å£ï¼Œæ”¯æŒæŒ‡å®šå¼€å§‹æ—¥æœŸ"""
        end_date = "20500101"

        try:
            if s_type == 'Industry':
                # ä½¿ç”¨åŸºç±»çš„é‡è¯•æœºåˆ¶
                df = self._retry_call(
                    ak.stock_board_industry_hist_em,
                    symbol=name,
                    start_date=start_date,
                    end_date=end_date,
                    adjust=""
                )
            else:
                df = self._retry_call(
                    ak.stock_board_concept_hist_em,
                    symbol=name,
                    start_date=start_date,
                    end_date=end_date,
                    adjust=""
                )
            return df
        except Exception as e:
            return pd.DataFrame()

    def save_data(self, df: pd.DataFrame, name: str):
        """æ¸…æ´—å¹¶æ‰§è¡Œ Upsert"""
        if df is None or df.empty:
            return False

        # 1. å­—æ®µæ˜ å°„ä¸æ¸…æ´—
        cols_map = {
            'æ—¥æœŸ': 'trade_date',
            'å¼€ç›˜': 'open',
            'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high',
            'æœ€ä½': 'low',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æ¶¨è·Œå¹…': 'pct_chg'
        }
        df = df.rename(columns=cols_map)

        # ç¡®ä¿å¿…å¤‡åˆ—å­˜åœ¨
        required_cols = ['trade_date', 'open', 'close', 'high', 'low', 'volume']
        if not all(col in df.columns for col in required_cols):
            return False

        df['sector_name'] = name
        df['trade_date'] = pd.to_datetime(df['trade_date']).dt.date

        # æ•°å€¼å‹å­—æ®µè½¬æ¢
        numeric_cols = ['open', 'close', 'high', 'low', 'volume', 'amount', 'pct_chg']
        for col in numeric_cols:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

        # é€‰æ‹©éœ€è¦çš„åˆ—
        final_df = df[['sector_name', 'trade_date', 'open', 'close', 'high', 'low', 'volume', 'amount', 'pct_chg']].dropna(subset=['trade_date'])

        if final_df.empty:
            return False

        # 2. å…¥åº“é€»è¾‘
        with self.engine.begin() as conn:
            # åˆ é™¤å·²å­˜åœ¨çš„æ•°æ®
            for _, row in final_df.iterrows():
                conn.execute(text(f"""
                    DELETE FROM {self.table_name}
                    WHERE sector_name = :sector_name
                    AND trade_date = :trade_date
                """), {
                    'sector_name': row['sector_name'],
                    'trade_date': row['trade_date']
                })

            # æ’å…¥æ–°æ•°æ®
            final_df.to_sql(self.table_name, conn, if_exists='append', index=False)

        return True

    def run(self):
        """æ‰§è¡Œæ¿å—Kçº¿é‡‡é›†"""
        self.log_collection_start()
        logger.info("ğŸš€ å¯åŠ¨ [æ¿å— K çº¿] æ™ºèƒ½åŒæ­¥ä»»åŠ¡...")

        try:
            # å¥åº·æ£€æŸ¥
            self._health_check()
        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            self.log_collection_end(False, str(e))
            return

        self._init_table()

        # è·å–æ‰€æœ‰æ¿å—åˆ—è¡¨
        try:
            df_sectors = pd.read_sql("SELECT DISTINCT sector_name, sector_type FROM stock_sector_map", self.engine)
        except Exception:
            logger.error("âŒ æ— æ³•è¯»å– stock_sector_map è¡¨ï¼Œè¯·å…ˆè¿è¡Œæ¿å—æ•°æ®é‡‡é›†ï¼")
            self.log_collection_end(False, "æ— æ¿å—æ•°æ®")
            return

        total = len(df_sectors)
        logger.info(f"ğŸ“‹ å¾…å¤„ç†æ¿å—æ€»æ•°: {total}")

        update_count = 0
        skip_count = 0

        for i, row in df_sectors.iterrows():
            name = row['sector_name']
            s_type = row['sector_type']

            # æ™ºèƒ½åˆ¤æ–­èµ·å§‹æ—¥æœŸ
            start_date = self.get_start_date(name)
            three_years_ago = (datetime.now() - timedelta(days=1095)).strftime("%Y%m%d")
            is_incremental = start_date != three_years_ago
            mode_str = f"å¢é‡[{start_date}]" if is_incremental else "å…¨é‡[3å¹´]"

            print(f"[{i+1}/{total}] {mode_str}åŒæ­¥: {name} ...", end="\r")

            # ä¸‹è½½æ•°æ®
            df_raw = self.fetch_data(name, s_type, start_date)

            # ä¿å­˜æ•°æ®
            if df_raw is not None and not df_raw.empty:
                if self.save_data(df_raw, name):
                    update_count += 1
            else:
                skip_count += 1

            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(self.request_delay)

        print(f"\nğŸ‰ åŒæ­¥å®Œæˆï¼æ›´æ–°/æ’å…¥æ¿å—æ•°: {update_count}, æ— æ–°æ•°æ®/è·³è¿‡: {skip_count}")
        self.log_collection_end(True, f"æ›´æ–° {update_count}/{total} ä¸ªæ¿å—")


if __name__ == "__main__":
    collector = SectorKlineCollector()
    collector.run()
