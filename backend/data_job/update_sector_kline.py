# è·å–æ¿å—æŒ‡æ•°kçº¿
import sys
import os
import time
import logging
import pandas as pd
import akshare as ak
from datetime import timedelta
from sqlalchemy import text
import ssl

# ================= ğŸš‘ ç½‘ç»œæ€¥æ•‘åŒ… (æ–°å¢éƒ¨åˆ†) =================
# 1. å¼ºåˆ¶å…³é—­ç³»ç»Ÿä»£ç† (è§£å†³ Mac å¼€ VPN å¯¼è‡´æ— æ³•è¿æ¥å›½å†…æ¥å£çš„é—®é¢˜)
# è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼é˜²æ­¢ requests åº“è‡ªåŠ¨è¯»å–ä½ çš„æ¢¯å­é…ç½®
for k in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
    if k in os.environ:
        del os.environ[k]

# 2. å¿½ç•¥ SSL è¯ä¹¦éªŒè¯ (è§£å†³ HTTPSConnectionPool æŠ¥é”™)
ssl._create_default_https_context = ssl._create_unverified_context
# ==========================================================
# ================= ç¯å¢ƒè·¯å¾„é€‚é… =================
# ç¡®ä¿è„šæœ¬èƒ½æ‰¾åˆ° backend/app ç›®å½• (æ— è®ºæ˜¯åœ¨æ ¹ç›®å½•è¿˜æ˜¯å­ç›®å½•è¿è¡Œ)
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../"))
if project_root not in sys.path:
    sys.path.append(project_root)

# å¯¼å…¥ä½ çš„é…ç½®æ ¸å¿ƒ
from app.core.database import get_engine

# ================= æ—¥å¿—é…ç½® =================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SectorKlineManager:
    def __init__(self):
        self.engine = get_engine()
        self.table_name = "sector_daily_prices"
        self.temp_table = "temp_sector_k_update"

    def _init_table(self):
        """ç¡®ä¿ç›®æ ‡è¡¨å­˜åœ¨"""
        with self.engine.begin() as conn:
            conn.execute(text(f"""
                CREATE TABLE IF NOT EXISTS {self.table_name} (
                    sector_name TEXT,
                    trade_date DATE,
                    open FLOAT,
                    close FLOAT,
                    high FLOAT,
                    low FLOAT,
                    volume FLOAT,
                    PRIMARY KEY (sector_name, trade_date)
                );
                CREATE INDEX IF NOT EXISTS idx_sector_date ON {self.table_name} (trade_date);
            """))

    def get_start_date(self, sector_name: str) -> str:
        """
        æ ¸å¿ƒé€»è¾‘ï¼šæ£€æŸ¥æ•°æ®åº“ï¼Œå†³å®šæ˜¯ã€å…¨é‡ä¸‹è½½ã€‘è¿˜æ˜¯ã€å¢é‡æ›´æ–°ã€‘
        è¿”å›æ ¼å¼: 'YYYYMMDD'
        """
        query = text(f"SELECT MAX(trade_date) FROM {self.table_name} WHERE sector_name = :name")
        try:
            with self.engine.connect() as conn:
                result = conn.execute(query, {"name": sector_name}).scalar()
            
            if result:
                # å¦‚æœæœ‰æ•°æ®ï¼Œä»æœ€åä¸€å¤©æ•°æ®çš„"ä¸‹ä¸€å¤©"å¼€å§‹ä¸‹è½½
                next_date = result + timedelta(days=1)
                return next_date.strftime("%Y%m%d")
            else:
                # å¦‚æœæ²¡æ•°æ®ï¼Œé»˜è®¤ä» 2000å¹´å¼€å§‹ (å…¨é‡)
                return "20000101"
        except Exception as e:
            logger.warning(f"è·å–èµ·å§‹æ—¥æœŸå¤±è´¥ï¼Œé»˜è®¤å…¨é‡ä¸‹è½½: {e}")
            return "20000101"

    def fetch_data(self, name: str, s_type: str, start_date: str) -> pd.DataFrame:
        """è°ƒç”¨ AkShare æ¥å£ï¼Œæ”¯æŒæŒ‡å®šå¼€å§‹æ—¥æœŸ"""
        # AkShare çš„æ¥å£é€šå¸¸æ˜¯ç”¨ end_date='20500101' æ¥ä»£è¡¨â€œç›´åˆ°æœ€æ–°â€
        end_date = "20500101" 
        
        try:
            if s_type == 'Industry':
                # æ³¨æ„ï¼šéƒ¨åˆ† Akshare æ¥å£å‚æ•°åå¯èƒ½ä¸åŒï¼Œè¿™é‡Œä»¥æ ‡å‡†æ¥å£ä¸ºä¾‹
                # ä¸œæ–¹è´¢å¯Œè¡Œä¸šæ¿å—
                df = ak.stock_board_industry_hist_em(
                    symbol=name, 
                    start_date=start_date, 
                    end_date=end_date, 
                    adjust=""
                )
            else:
                # ä¸œæ–¹è´¢å¯Œæ¦‚å¿µæ¿å—
                df = ak.stock_board_concept_hist_em(
                    symbol=name, 
                    start_date=start_date, 
                    end_date=end_date, 
                    adjust=""
                )
            return df
        except Exception as e:
            # æŸäº›æä¸ªåˆ«æ¿å—å¯èƒ½æ¥å£æŠ¥é”™ï¼Œæˆ–è€…è¯¥æ—¶é—´æ®µæ— æ•°æ®
            return pd.DataFrame()

    def save_data(self, df: pd.DataFrame, name: str):
        """æ¸…æ´—å¹¶æ‰§è¡Œ Upsert (æ›´æ–°æ’å…¥)"""
        if df is None or df.empty:
            return False

        # 1. å­—æ®µæ˜ å°„ä¸æ¸…æ´—
        cols_map = {
            'æ—¥æœŸ': 'trade_date', 'å¼€ç›˜': 'open', 'æ”¶ç›˜': 'close',
            'æœ€é«˜': 'high', 'æœ€ä½': 'low', 'æˆäº¤é‡': 'volume'
        }
        # å…¼å®¹å¯èƒ½å­˜åœ¨çš„ä¸åŒåˆ—å
        df = df.rename(columns=cols_map)
        
        # ç¡®ä¿å¿…å¤‡åˆ—å­˜åœ¨
        required_cols = ['trade_date', 'open', 'close', 'high', 'low', 'volume']
        if not all(col in df.columns for col in required_cols):
            return False

        df['sector_name'] = name
        df['trade_date'] = pd.to_datetime(df['trade_date']).dt.date
        
        # è¿‡æ»¤æ‰éäº¤æ˜“æ—¥æˆ–ç©ºæ•°æ®
        final_df = df[['sector_name', 'trade_date', 'open', 'close', 'high', 'low', 'volume']].dropna()

        if final_df.empty:
            return False

        # 2. å…¥åº“é€»è¾‘ (ä½¿ç”¨ä¸´æ—¶è¡¨ + Upsert ä»¥ä¿è¯å¹‚ç­‰æ€§)
        with self.engine.begin() as conn:
            # å†™å…¥ä¸´æ—¶è¡¨
            final_df.to_sql(self.temp_table, conn, if_exists='replace', index=False)
            
            # æ‰§è¡Œåˆå¹¶ï¼šå¦‚æœ (name, date) å†²çªï¼Œåˆ™æ›´æ–°æ•°æ®ï¼ˆä¿®å¤å†å²ï¼‰ï¼Œå¦åˆ™æ’å…¥
            upsert_sql = text(f"""
                INSERT INTO {self.table_name} 
                SELECT * FROM {self.temp_table}
                ON CONFLICT (sector_name, trade_date) 
                DO UPDATE SET 
                    open = EXCLUDED.open,
                    close = EXCLUDED.close,
                    high = EXCLUDED.high,
                    low = EXCLUDED.low,
                    volume = EXCLUDED.volume;
            """)
            conn.execute(upsert_sql)
            
            # æ¸…ç†ä¸´æ—¶è¡¨ (å¯é€‰ï¼Œdrop table)
            # conn.execute(text(f"DROP TABLE {self.temp_table}"))
            
        return True

    def run(self):
        logger.info("ğŸš€ å¯åŠ¨ [æ¿å— K çº¿] æ™ºèƒ½åŒæ­¥ä»»åŠ¡...")
        self._init_table()

        # 1. è·å–æ‰€æœ‰æ¿å—åˆ—è¡¨
        try:
            df_sectors = pd.read_sql("SELECT DISTINCT sector_name, sector_type FROM stock_sector_map", self.engine)
        except Exception:
            logger.error("âŒ æ— æ³•è¯»å– stock_sector_map è¡¨ï¼Œè¯·å…ˆè¿è¡Œ init_sector_data.pyï¼")
            return

        total = len(df_sectors)
        logger.info(f"ğŸ“‹ å¾…å¤„ç†æ¿å—æ€»æ•°: {total}")

        update_count = 0
        skip_count = 0

        for i, row in df_sectors.iterrows():
            name = row['sector_name']
            s_type = row['sector_type']
            
            # 2. æ™ºèƒ½åˆ¤æ–­èµ·å§‹æ—¥æœŸ
            start_date = self.get_start_date(name)
            is_incremental = start_date != "20000101"
            mode_str = f"å¢é‡[{start_date}]" if is_incremental else "å…¨é‡"

            print(f"[{i+1}/{total}] {mode_str}åŒæ­¥: {name} ...", end="\r")

            # 3. ä¸‹è½½æ•°æ®
            df_raw = self.fetch_data(name, s_type, start_date)

            # 4. ä¿å­˜æ•°æ®
            if not df_raw.empty:
                if self.save_data(df_raw, name):
                    update_count += 1
            else:
                skip_count += 1
            
            # ç¤¼è²Œçˆ¬è™«ï¼Œé¿å…è¢«å° IP
            time.sleep(0.05)

        print(f"\nğŸ‰ åŒæ­¥å®Œæˆï¼æ›´æ–°/æ’å…¥æ¿å—æ•°: {update_count}, æ— æ–°æ•°æ®/è·³è¿‡: {skip_count}")

if __name__ == "__main__":
    manager = SectorKlineManager()
    manager.run()