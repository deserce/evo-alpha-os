"""
EvoAlpha OS - æ–°é—»èˆ†æƒ…æ•°æ®é‡‡é›†
é‡‡é›†è´¢ç»æ–°é—»å¹¶è¿›è¡Œè‚¡ç¥¨å…³è”å’Œæƒ…ç»ªåˆ†æ
"""

import sys
import os
import time
import logging
import pandas as pd
import akshare as ak
from sqlalchemy import text
from datetime import datetime, timedelta
import re

# ================= ç½‘ç»œæ€¥æ•‘åŒ… =================
for k in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
    if k in os.environ:
        del os.environ[k]

import ssl
ssl._create_default_https_context = ssl._create_unverified_context
# ==========================================================

# ================= ç¯å¢ƒè·¯å¾„é€‚é… =================
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_dir = os.path.abspath(os.path.join(current_dir, ".."))
if backend_dir not in sys.path:
    sys.path.insert(0, backend_dir)

from app.core.database import get_active_engines

# ================= æ—¥å¿—é…ç½® =================
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class NewsManager:
    def __init__(self):
        self.engines = get_active_engines()
        self.articles_table = "news_articles"
        self.relation_table = "news_stock_relation"

    def _init_tables(self):
        """åˆå§‹åŒ–æ–°é—»ç›¸å…³è¡¨"""
        for mode, engine in self.engines:
            logger.info(f"ğŸ› ï¸  [{mode}] åˆ›å»ºæ–°é—»è¡¨...")
            try:
                with engine.begin() as conn:
                    # æ–°é—»æ–‡ç« è¡¨
                    conn.execute(text(f"""
                        CREATE TABLE IF NOT EXISTS {self.articles_table} (
                            article_id VARCHAR(50) PRIMARY KEY,
                            title VARCHAR(200),
                            content TEXT,
                            source VARCHAR(50),
                            publish_time TIMESTAMP,
                            url VARCHAR(500),
                            sentiment_type VARCHAR(10),
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        );
                    """))

                    # æ–°é—»-è‚¡ç¥¨å…³è”è¡¨
                    conn.execute(text(f"""
                        CREATE TABLE IF NOT EXISTS {self.relation_table} (
                            article_id VARCHAR(50),
                            symbol VARCHAR(20),
                            relevance_score FLOAT,
                            sentiment_type VARCHAR(10),
                            PRIMARY KEY (article_id, symbol)
                        );
                    """))

                    # åˆ›å»ºç´¢å¼•
                    conn.execute(text(f"CREATE INDEX IF NOT EXISTS idx_news_time ON {self.articles_table} (publish_time);"))
                    conn.execute(text(f"CREATE INDEX IF NOT EXISTS idx_news_symbol ON {self.relation_table} (symbol);"))

                    logger.success(f"âœ… [{mode}] æ–°é—»è¡¨åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                logger.error(f"âŒ [{mode}] åˆ›å»ºæ–°é—»è¡¨å¤±è´¥: {e}")

    def fetch_news_em(self, date_str=None):
        """
        ä»ä¸œæ–¹è´¢å¯Œè·å–æ–°é—»

        Args:
            date_str: æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆYYYYMMDDï¼‰ï¼Œé»˜è®¤ä¸ºä»Šå¤©

        Returns:
            DataFrame: æ–°é—»æ•°æ®
        """
        try:
            if date_str is None:
                date_str = datetime.now().strftime('%Y%m%d')

            # è·å–ä¸œæ–¹è´¢å¯Œæ–°é—»
            df = ak.stock_news_em(date=date_str)

            if df.empty:
                logger.warning(f"âš ï¸  {date_str} æ— æ–°é—»æ•°æ®")
                return None

            # æ•°æ®æ¸…æ´—
            df = df.rename(columns={
                'æ–°é—»æ ‡é¢˜': 'title',
                'æ–°é—»å†…å®¹': 'content',
                'æ–°é—»æ¥æº': 'source',
                'å‘å¸ƒæ—¶é—´': 'publish_time',
                'æ–‡ç« é“¾æ¥': 'url',
            })

            # ç”Ÿæˆ article_idï¼ˆä½¿ç”¨URLçš„å“ˆå¸Œå€¼ä½œä¸ºIDï¼‰
            df['article_id'] = df['url'].apply(lambda x: f"EM_{hash(x) % 10000000000:08d}")

            # æ—¶é—´è½¬æ¢
            df['publish_time'] = pd.to_datetime(df['publish_time'])

            # é»˜è®¤æƒ…ç»ªç±»å‹ï¼ˆåç»­å¯ä»¥ä¼˜åŒ–ï¼‰
            df['sentiment_type'] = 'neutral'

            logger.info(f"  âœ… ä¸œæ–¹è´¢å¯Œ: {len(df)} æ¡æ–°é—»")
            return df

        except Exception as e:
            logger.error(f"âŒ ä¸œæ–¹è´¢å¯Œæ–°é—»é‡‡é›†å¤±è´¥: {e}")
            return None

    def extract_stock_symbols(self, text):
        """
        ä»æ–‡æœ¬ä¸­æå–è‚¡ç¥¨ä»£ç 

        Args:
            text: æ–°é—»æ–‡æœ¬

        Returns:
            list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        # åŒ¹é…6ä½æ•°å­—ï¼ˆå¯èƒ½æ˜¯è‚¡ç¥¨ä»£ç ï¼‰
        pattern = r'\b(00|30|60|68)\d{4}\b'
        matches = re.findall(pattern, text)

        # å»é‡
        symbols = list(set(matches))
        return symbols

    def analyze_sentiment(self, title, content):
        """
        ç®€å•çš„æƒ…ç»ªåˆ†æï¼ˆåŸºäºå…³é”®è¯ï¼‰

        Args:
            title: æ–°é—»æ ‡é¢˜
            content: æ–°é—»å†…å®¹

        Returns:
            str: 'positive', 'negative', 'neutral'
        """
        # åˆ©å¥½å…³é”®è¯
        positive_keywords = ['å¤§æ¶¨', 'ä¸Šæ¶¨', 'åˆ©å¥½', 'çªç ´', 'å¢é•¿', 'ç›ˆåˆ©', 'æ¶¨åœ',
                            'å›è´­', 'å¢æŒ', 'æ”¶è´­', 'ä¸šç»©', 'åˆ›æ–°é«˜', 'é¢†æ¶¨']

        # åˆ©ç©ºå…³é”®è¯
        negative_keywords = ['å¤§è·Œ', 'ä¸‹è·Œ', 'åˆ©ç©º', 'è·Œç ´', 'ä¸‹é™', 'äºæŸ', 'è·Œåœ',
                            'å‡æŒ', 'ä¸šç»©', 'åˆ›æ–°ä½', 'é¢†è·Œ', 'è°ƒæŸ¥', 'å¤„ç½š']

        # åˆå¹¶æ–‡æœ¬
        text = title + ' ' + str(content)

        # ç»Ÿè®¡å…³é”®è¯
        positive_count = sum(1 for kw in positive_keywords if kw in text)
        negative_count = sum(1 for kw in negative_keywords if kw in text)

        # åˆ¤æ–­æƒ…ç»ª
        if positive_count > negative_count:
            return 'positive'
        elif negative_count > positive_count:
            return 'negative'
        else:
            return 'neutral'

    def save_news(self, df):
        """
        ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“

        Args:
            df: æ–°é—»æ•°æ®
        """
        if df is None or df.empty:
            return

        for mode, engine in self.engines:
            try:
                with engine.begin() as conn:
                    # ä¿å­˜æ–‡ç« 
                    articles_df = df[['article_id', 'title', 'content', 'source', 'publish_time', 'url', 'sentiment_type']]

                    # åˆ é™¤å·²å­˜åœ¨çš„æ–‡ç« 
                    conn.execute(text(f"""
                        DELETE FROM {self.articles_table}
                        WHERE article_id IN ({','.join([f"'{aid}'" for aid in articles_df['article_id']])})
                    """))

                    # æ’å…¥æ–°æ–‡ç« 
                    articles_df.to_sql(self.articles_table, conn, if_exists='append', index=False)

                    # ä¿å­˜è‚¡ç¥¨å…³è”
                    relations = []
                    for _, row in df.iterrows():
                        symbols = self.extract_stock_symbols(row['title'] + ' ' + str(row['content']))

                        for symbol in symbols:
                            relations.append({
                                'article_id': row['article_id'],
                                'symbol': symbol,
                                'relevance_score': 1.0,  # é»˜è®¤ç›¸å…³æ€§
                                'sentiment_type': row['sentiment_type']
                            })

                    if relations:
                        relations_df = pd.DataFrame(relations)

                        # åˆ é™¤æ—§å…³è”
                        conn.execute(text(f"""
                            DELETE FROM {self.relation_table}
                            WHERE article_id IN ({','.join([f"'{aid}'" for aid in articles_df['article_id']])})
                        """))

                        # æ’å…¥æ–°å…³è”
                        relations_df.to_sql(self.relation_table, conn, if_exists='append', index=False)

                    logger.info(f"âœ… [{mode}] ä¿å­˜ {len(df)} æ¡æ–°é—»ï¼Œ{len(relations)} ä¸ªè‚¡ç¥¨å…³è”")

            except Exception as e:
                logger.error(f"âŒ [{mode}] ä¿å­˜æ–°é—»å¤±è´¥: {e}")

    def run(self, days=3):
        """
        æ‰§è¡Œæ–°é—»é‡‡é›†

        Args:
            days: é‡‡é›†æœ€è¿‘å‡ å¤©çš„æ–°é—»
        """
        logger.info("ğŸš€ å¼€å§‹é‡‡é›†æ–°é—»èˆ†æƒ…æ•°æ®...")

        # åˆå§‹åŒ–è¡¨
        self._init_tables()

        # é‡‡é›†æœ€è¿‘å‡ å¤©çš„æ–°é—»
        for i in range(days):
            date = datetime.now() - timedelta(days=i)
            date_str = date.strftime('%Y%m%d')

            logger.info(f"ğŸ“° é‡‡é›† {date_str} çš„æ–°é—»...")

            try:
                # è·å–æ–°é—»
                df = self.fetch_news_em(date_str)

                if df is not None:
                    # åˆ†ææƒ…ç»ª
                    df['sentiment_type'] = df.apply(
                        lambda row: self.analyze_sentiment(row['title'], row['content']),
                        axis=1
                    )

                    # ä¿å­˜åˆ°æ•°æ®åº“
                    self.save_news(df)

                # é¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(1)

            except Exception as e:
                logger.error(f"âŒ {date_str} æ–°é—»é‡‡é›†å¤±è´¥: {e}")
                continue

        logger.success("ğŸ‰ æ–°é—»èˆ†æƒ…é‡‡é›†å®Œæˆ")


if __name__ == "__main__":
    manager = NewsManager()
    manager.run(days=3)  # é»˜è®¤é‡‡é›†æœ€è¿‘3å¤©
